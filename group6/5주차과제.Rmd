---
title: "5thweek"
output:
  html_document: default
  pdf_document: default
---
8.3.1
a.
 $\text{Var}(y_{i, j} \mid \mu, \tau^2)$ should  be larger since it obtains variability from both sampling a group
 and from within the group
 
b.
1. 일단, $\text{Cov}(y_{i_1, j}, y_{i_2, j} \mid \theta_j, \sigma^2)$ 는 exchangability의 의해 conditional independent 하므로, 0의 값을 가진다.

2. 같은 그룹에서 나왔기 때문같 둘이 영향을, 특히 아마 +의 영향을 가질 것이다.

c.
\begin{align}
\text{Var}(y_{i, j} \mid \theta_j, \sigma^2) &= \sigma^2 \\
\text{Var}(\bar{y}_{\cdot, j} \mid \theta_j, \sigma^2) &= \sigma^2 / n_j \\
\text{Cov}(y_{i_1, j}, y_{i_2, j} \mid \theta_j, \sigma^2) &= \mathbb{E}(y_{i_1, j}y_{i_2, j}) - \mathbb{E}(y_{i_1, j})\mathbb{E}(y_{i_2, j}) \\
&= \mathbb{E}(y_{i_1, j})\mathbb{E}(y_{i_2, j}) - \mathbb{E}(y_{i_1, j})\mathbb{E}(y_{i_2, j})\\
&= 0 \\
& \\
\text{Var}(y_{i, j} \mid \mu, \tau^2) &= \text{Var}(\mathbb{E}(y_{i, j} \mid \theta_j, \sigma^2) \mid \mu, \tau^2) + \mathbb{E}(\text{Var}(y_{i, j} \mid \theta_j, \sigma^2) \mid \mu, \tau^2)  \\
&= \text{Var}(\theta_j \mid \mu, \tau^2) + \mathbb{E}(\sigma^2 \mid \mu, \tau^2) \\
&= \tau^2 + \sigma^2 \\

\text{Var}(\bar{y}_{\cdot, j} \mid \mu, \tau^2) &= \text{Var}(\mathbb{E}(\bar{y}_{\cdot, j} \mid \theta_j, \sigma^2) \mid \mu, \tau^2) + \mathbb{E}(\text{Var}(\bar{y}_{\cdot, j} \mid \theta_j, \sigma^2) \mid \mu, \tau^2)  \\
&= \text{Var}(\theta_j \mid \mu, \tau^2) + \mathbb{E}(\sigma^2 / n_j \mid \mu, \tau^2) \\
&= \tau^2 + (\sigma^2 / n_j) \\

\text{Cov}(y_{i_1, j}, y_{i_2, j} \mid \mu, \tau^2) &= \text{E}(\text{Cov}(y_{i_1, j}, y_{i_2, j} \mid \theta_j, \sigma^2) \mid \mu, \tau^2) + \text{Cov}(\mathbb{E}(y_{i_1, j} \mid \theta_j, \sigma^2), \mathbb{E}(y_{i_2, j} \mid \theta_j, \sigma^2)) \\
&= \text{E}(0 \mid \mu, \tau^2) + \text{Cov}(\mathbb{E}(y_{i_1, j} \mid \theta_j, \sigma^2), \mathbb{E}(y_{i_2, j} \mid \theta_j, \sigma^2)) \\
&= \text{Cov}(\theta_j, \theta_j) \\
&= \text{Var}(\theta_j) \\
&= \tau^2
\end{align}

d.
theta를 알고 있을 때는 mu가 더 이상 data에 의존하지 않는다.


8.3.3
a.
``` {r}
library(tidyverse)
school = list()
for(i in 1:8){
    url = paste0('http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/school', as.character(i), '.dat')
    school[paste0('school', as.character(i))] = read.csv(url)
}
school_df <- data_frame(id = seq_along(school), school) %>% unnest %>% as.data.frame()
colnames(school_df) <- c('school_id', 'score')
```

Setting model for JAGS
```{R}
modelString <- "
model{

## likelihood
for (i in 1:N){
y[i] ~ dnorm(mu_j[id[i]], invsigma2)
}

##hyperprior
mu ~ dnorm(mu0, 1/g0^2)
invtau2 ~ dgamma(a_t, b_t)
tau <- sqrt(pow(invtau2, -1))

##prior
for (j in 1:J){
mu_j[j] ~ dnorm(mu, invtau2)
}
invsigma2 ~ dgamma(a_g, b_g)
sigma <- sqrt(pow(invsigma2, -1))
}
"
```

matching data to parameters
```{r}
y <- school_df %>% pull(score)
id <- school_df %>% pull(school_id)
N <- length(y)
J <- length(unique(id))

initsfunction <- function(chain){
    .RNG.seed <- c(1,2)[chain]
    .RNG.name <- c('base::Super-Duper',
                   'base::Wichmann-Hill')[chain]
    return(list(.RNG.seed=.RNG.seed,
                .RNG.name=.RNG.name))
}

the_data <- list('y'=y, 'id'=id, 'N'=N, 'J'=J,
                 'mu0'=7, 'g0'=sqrt(5),
                 'a_t'=1, 'b_t'=10,
                 'a_g'=1, 'b_g'=15)
```

running JAGS
```{r}
library(runjags)
runjags.options(silent.runjags=TRUE, silent.jags=TRUE)
posterior <- run.jags(modelString,
                      n.chains = 1,
                      data = the_data,
                      monitor = c('mu', 'tau', 'mu_j', 'sigma'),
                      adapt = 1000,
                      burnin = 5000,
                      sample = 5000,
                      thin = 1,
                      inits = initsfunction)
```

summary
```{R}
summary(posterior)
```
=> 유효데이타가 충분하다.

b.

```{R}
library(coda)
mu_draws <- as.mcmc(posterior, vars='mu')
mu_draws <- data.frame(mu_draws)$mu # why 'mu' includes mu_j

tau_draws <- as.mcmc(posterior, vars='tau')
tau_draws <- as.numeric(tau_draws)

sigma_draws <- as.mcmc(posterior, vars='sigma')
sigma_draws <- as.numeric(sigma_draws)
temp1 <- as.numeric(quantile(mu_draws, c(0.025, 0.975)))

temp2 <- as.numeric(quantile(tau_draws, c(0.025, 0.975)))

temp3 <- as.numeric(quantile(sigma_draws, c(0.025, 0.975)))

quantile_df <- data.frame(mu = temp1, tau = temp2, sigma = temp3)
rownames(quantile_df) <- c('2.5%', '97.5%')

quantile_df
```





```{R}
library(invgamma)
temp_df <- data.frame(mu = mu_draws, tau = tau_draws, sigma = sigma_draws)

temp_df_long <- temp_df %>% gather(parameter, value, c('mu', 'tau', 'sigma'))

ggplot(temp_df_long, aes(value, color=parameter)) + geom_density() +
    scale_color_manual(values = c("red", "green", "blue")) +
    stat_function(fun=dnorm, args=list(mean=7, sd=sqrt(5)), 
                  colour="red", size=0.5) +
    stat_function(fun=dinvgamma, args=list(shape=1, rate=15),
                  colour="green", size=0.5) +
    stat_function(fun=dinvgamma, args=list(shape=1, rate=10),
                  colour="blue", size=0.5)
```



c.
```{r}
R = tau_draws^2/(tau_draws^2 + sigma_draws^2)

df <- data.frame(R = R)
ggplot(df, aes(x=R)) +
  geom_density() +
  labs(title='Density of R')
```



d.
```{R}
mu_j_draws <- data.frame(as.mcmc(posterior, vars='mu_j'))

colnames(mu_j_draws) <- c('mu1', 'mu2', 'mu3', 'mu4', 'mu5', 'mu6', 'mu7', 'mu8')

mu_j_draws %>% transmute(bigger=mu6>mu7) %>% summarize(mean(bigger))
```

```{r}
temp <- mu_j_draws %>% transmute(mu7<mu1, mu7<mu2, mu7<mu3, mu7<mu4, mu7<mu5,
                                  mu7<mu6, mu7<mu8)
head(temp)
```

```{r}
  mean(apply(temp, 1, all))
```

